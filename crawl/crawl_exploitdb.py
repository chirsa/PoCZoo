import fnmatch
import random

import requests
import time
from datetime import datetime
import pymongo
from fake_headers import Headers
from pymongo import MongoClient
import json
import os
from src.dataProceScript.spider_base import BaseSpider

from src.dataProceScript.dataProce import jsonToList, queryrepeat, insert_mongo, init_item, fieldToValue, getDeepin, isInDeepin
from src.dataProceScript.Setting import *
class exploitdb(BaseSpider):
    def __init__(self, db, vulnName):
        super().__init__(db, vulnName)
        self.key = 'id'
        self.path = f'{DATA_PATH}/{CURRENT_TIME}/{vulnName}'
        if not os.path.exists(self.path):
            os.makedirs(self.path)


        self.starturl = 'https://www.exploit-db.com/?draw=1&columns[0][data]=date_published&columns[0][name]=date_published&columns[0][searchable]=true&columns[0][orderable]=true&columns[0][search][value]=&columns[0][search][regex]=false&columns[1][data]=download&columns[1][name]=download&columns[1][searchable]=false&columns[1][orderable]=false&columns[1][search][value]=&columns[1][search][regex]=false&columns[2][data]=application_md5&columns[2][name]=application_md5&columns[2][searchable]=true&columns[2][orderable]=false&columns[2][search][value]=&columns[2][search][regex]=false&columns[3][data]=verified&columns[3][name]=verified&columns[3][searchable]=true&columns[3][orderable]=false&columns[3][search][value]=&columns[3][search][regex]=false&columns[4][data]=description&columns[4][name]=description&columns[4][searchable]=true&columns[4][orderable]=false&columns[4][search][value]=&columns[4][search][regex]=false&columns[5][data]=type_id&columns[5][name]=type_id&columns[5][searchable]=true&columns[5][orderable]=false&columns[5][search][value]=&columns[5][search][regex]=false&columns[6][data]=platform_id&columns[6][name]=platform_id&columns[6][searchable]=true&columns[6][orderable]=false&columns[6][search][value]=&columns[6][search][regex]=false&columns[7][data]=author_id&columns[7][name]=author_id&columns[7][searchable]=false&columns[7][orderable]=false&columns[7][search][value]=&columns[7][search][regex]=false&columns[8][data]=code&columns[8][name]=code.code&columns[8][searchable]=true&columns[8][orderable]=true&columns[8][search][value]=&columns[8][search][regex]=false&columns[9][data]=id&columns[9][name]=id&columns[9][searchable]=false&columns[9][orderable]=true&columns[9][search][value]=&columns[9][search][regex]=false&order[0][column]=9&order[0][dir]=desc&start=0&length=120&search[value]=&search[regex]=false&author=&port=&type=&tag=&platform=&_=1674651126796'
        self.url = 'https://www.exploit-db.com/?draw={}&columns[0][data]=date_published&columns[0][name]=date_published&columns[0][searchable]=true&columns[0][orderable]=true&columns[0][search][value]=&columns[0][search][regex]=false&columns[1][data]=download&columns[1][name]=download&columns[1][searchable]=false&columns[1][orderable]=false&columns[1][search][value]=&columns[1][search][regex]=false&columns[2][data]=application_md5&columns[2][name]=application_md5&columns[2][searchable]=true&columns[2][orderable]=false&columns[2][search][value]=&columns[2][search][regex]=false&columns[3][data]=verified&columns[3][name]=verified&columns[3][searchable]=true&columns[3][orderable]=false&columns[3][search][value]=&columns[3][search][regex]=false&columns[4][data]=description&columns[4][name]=description&columns[4][searchable]=true&columns[4][orderable]=false&columns[4][search][value]=&columns[4][search][regex]=false&columns[5][data]=type_id&columns[5][name]=type_id&columns[5][searchable]=true&columns[5][orderable]=false&columns[5][search][value]=&columns[5][search][regex]=false&columns[6][data]=platform_id&columns[6][name]=platform_id&columns[6][searchable]=true&columns[6][orderable]=false&columns[6][search][value]=&columns[6][search][regex]=false&columns[7][data]=author_id&columns[7][name]=author_id&columns[7][searchable]=false&columns[7][orderable]=false&columns[7][search][value]=&columns[7][search][regex]=false&columns[8][data]=code&columns[8][name]=code.code&columns[8][searchable]=true&columns[8][orderable]=true&columns[8][search][value]=&columns[8][search][regex]=false&columns[9][data]=id&columns[9][name]=id&columns[9][searchable]=false&columns[9][orderable]=true&columns[9][search][value]=&columns[9][search][regex]=false&order[0][column]=9&order[0][dir]=desc&start={}&length=120&search[value]=&search[regex]=false&author=&port=&type=&tag=&platform=&_={}'

        self.start = 0
        self.draw = 1
        self.index = 1674651126797

    def get_headers(self):
        header = Headers(
            browser='chrome',
            os='win',
            headers=True
        ).generate()
        # 获取当前时间
        current_time = datetime.now()

        # 将时间转换成指定格式
        formatted_time = current_time.strftime("%a, %d-%b-%Y %H:%M:%S GMT")
        # print(formatted_time)
        headers = {
            'User-Agent': header['User-Agent'],
            'Host': 'www.exploit-db.com',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate, br",
            'Sec-Fetch-Mode': 'cors',
            'X-Requested-With': 'XMLHttpRequest',
            'set-cookie': f'XSRF-TOKEN=eyJpdiI6InJLbmtwbzJuMnptMGtwWnRHZ2tlOHc9PSIsInZhbHVlIjoiTE5iaTNVUWs3SkRwTGxMd3EwdHhRYnBjRVpVdm9EemxGWkJIXC83VW9WNCtMTDhHN1lCUFRXdGhUVW12ZmVQTDgiLCJtYWMiOiI1Nzk1ZDZlYjJmMjAyYjllZjNjMzU0OTA0ZmM0ZTliNTMxNmQyYzk3MDQ0ZTdjNzcxMTFjODcyYWM2NmU5NDZlIn0%3D; expires={formatted_time}; Max-Age=7200; path=/; secure;HttpOnly;Secure'
        }

        return headers

    def get_total(self):
        req = self.get(url=self.starturl, headers=self.get_headers())
        if req and req.status_code == 200:
            html = req.json()
            total = html['recordsTotal']
            return total

    def get_html(self, url,draw):
        headers = self.get_headers()
        # 增加重连接次数：
        requests.DEFAULT_RETRIES = 5
        session = requests.session()
        # 关闭多余连接
        session.keep_alive = False
        req = session.get(url=url, headers=headers)
        if req and req.status_code == 200:
            html = req.json()
            self.parse_html(html,draw)

    def parse_html(self, html,draw):
        vul_list = html['data']
        filename = os.path.join(self.path, str(draw)+'.json')

        with open(filename, 'w') as f:
            json.dump(vul_list, f)


    def crawl(self):
        self.total = self.get_total()
        self.logger.info(f'exploitDB一共有{self.total}个漏洞！需要爬取{self.total // 120+1}页：')
        # 若发生中断能在中断位置继续爬取
        try:
            self.getDetail()
        except Exception as e:
            self.logger.error(f'爬取失败，错误信息：{e},{self.draw},{self.start},{self.index}')
            self.getDetail()
        # print(f'----------{self.vulnName} 爬取完成----------')
        self.logger.info(f'----------{self.vulnName} 爬取完成----------')

    def getDetail(self):
        while (self.draw <= (self.total // 120 + 2)):
            url = self.url.format(self.draw, self.start, self.index)
            self.get_html(url, self.draw)
            self.draw += 1
            self.start += 120
            self.index += 1
            random_time = random.uniform(1, 3)
            time.sleep(random_time)
    def exploitdbToMongo(self):
        print(f'----------{self.vulnName} 开始存储----------')
        for root, dirnames, filenames in os.walk(self.path):
            for filename in fnmatch.filter(filenames, '*.json'):
                filepath = os.path.join(root, filename)  # 获取文件的完整路径
                # print(filepath)
                data = jsonToList(filepath)
                insert_mongo(self.collection, data, self.key)
        # 查重
        # queryrepeat(self.vulnName, self.collection, self.key)
        print(f'----------{self.vulnName} 存储完成----------')

    def dataPreProc(self):
        print(f'----------{self.vulnName} 开始数据预处理----------')
        collection = self.collection
        system = self.system
        # 先把总数据表中对应数据源所有数据删除
        query = {'source': self.vulnName}
        result = system.delete_many(query)
        # print(f"删除了 {result.deleted_count} 条数据。")
        count = 1
        for doc in collection.find():
            item = init_item(self.vulnName)
            item['source_id'] = doc['id'] if doc['id'] is not None else 'null'
            item['date'] =  'null'
            item['details'] = doc['description'][1] if doc['description'] is not None else 'null'
            item['title'] = item['details']
            item['type'] = doc['type_id'] if doc['type_id'] is not None else 'null'
            item['platform'] = doc['platform_id'] if doc['platform_id'] is not None else 'null'
            item['author'] = doc['author_id'][1] if doc['author_id'][1] is not None else 'null'
            item['vul_id'] = f"006_{str(count).zfill(6)}"
            count += 1
            # 关联的cve有多个时，只保留第一个
            for cve in fieldToValue(doc, 'code'):
                # print(cve)
                item['cve_id'] = f"CVE-{doc['code'][0]['code']}"
                break
            if item['cve_id'] != 'null':
                item['software_version'] = isInDeepin(item['cve_id'])
            # 其他字段丢进related
            related_data = {key: doc[key] for key in doc if
                            key not in ['_id',"id", "description", "type_id", "platform_id"
                                ,'author_id','code','type','platform','author']}
            # 将所有字段转换为字符串类型
            related_data = {key: str(val) for key, val in related_data.items()}
            item['related'] = related_data
            # 数据预处理前存入的数据库以及做过去重，这里可以直接存进
            system.insert_one(item)
        print(f'----------{self.vulnName} 数据预处理完成----------')

    def run(self):
        self.collection.drop()
        self.crawl()
        self.exploitdbToMongo()
        self.count = self.collection.count_documents({})
        self.logger.info(f'{self.vulnName}共计爬取{self.count}条数据')
        # self.dataPreProc()



# if __name__=='__main__':
#     # 获取当前时间
#     start_time = time.time()
#     # 连接 MongoDB 数据库
#     client = MongoClient('localhost', 27017)
#     # 获取指定数据库和集合
#     db = client['306Project']
#     collection = db['exploitDB']

#     system = db['system']
#     agent = Exploit('exploitDB',collection,'id',system)

#     agent.run()

#     client.close()
#     # 获取程序结束时间
#     end_time = time.time()
#     # 计算程序耗时
#     duration = end_time - start_time
#     # 打印程序耗时
#     print(f"程序耗时：{duration} 秒")